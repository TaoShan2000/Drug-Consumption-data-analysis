trainDat=read.csv('E:/STAT 362/362 proj/feature_selection_dummies.csv',header=TRUE)
target=read.csv('E:/STAT 362/362 proj/dfnew.csv',header=TRUE)
trainDat$Cannabis<-as.factor(target$Cannabis)


library(caret)
ctrl <- trainControl(method = "cv",
                     number = 10)

gbm.Grid = expand.grid(interaction.depth = c(2,3,4,5,6), 
                       # n.trees = (1:5)100, 
                       shrinkage = c(0.1, 0.05, 0.01),
                       n.minobsinnode = 10) 
gbm.cv.model <- train(Cannabis ~ ., data = trainDat,
                      method = "gbm",
                      trControl = ctrl,
                      tuneGrid = gbm.Grid,
                      verbose = FALSE,na.action = na.omit)
gbm.cv.model

boost.cv.pred = predict(gbm.cv.model, newdata = target)
mean(boost.cv.pred != target$Cannabis)

################################################
# > gbm.cv.model
# Stochastic Gradient Boosting 
# 
# 1884 samples
# 32 predictor
# 7 classes: '0', '1', '2', '3', '4', '5', '6' 
# 
# No pre-processing
# Resampling: Cross-Validated (10 fold) 
# Summary of sample sizes: 1692, 1693, 1692, 1691, 1693, 1690, ... 
# Resampling results across tuning parameters:
#   
#   shrinkage  interaction.depth  n.trees  Accuracy   Kappa    
# 0.01       2                  100      0.4696349  0.3279654
# 0.01       2                  200      0.4877148  0.3521462
# 0.01       2                  300      0.4829077  0.3492190
# 0.01       2                  400      0.4855532  0.3542710
# 0.01       2                  500      0.4903406  0.3622636
# 0.01       3                  100      0.4807799  0.3438381
# 0.01       3                  200      0.4887816  0.3555625
# 0.01       3                  300      0.4893106  0.3584193
# 0.01       3                  400      0.4898510  0.3619595
# 0.01       3                  500      0.4957163  0.3716442
# 0.01       4                  100      0.4941008  0.3609362
# 0.01       4                  200      0.4935829  0.3630879
# 0.01       4                  300      0.4935802  0.3656985
# 0.01       4                  400      0.4951985  0.3706053
# 0.01       4                  500      0.4983985  0.3763596
# 0.01       5                  100      0.4887702  0.3546151
# 0.01       5                  200      0.4925050  0.3622293
# 0.01       5                  300      0.4919816  0.3650500
# 0.01       5                  400      0.4946695  0.3713518
# 0.01       5                  500      0.4930906  0.3706973
# 0.01       6                  100      0.4893247  0.3564911
# 0.01       6                  200      0.4930340  0.3646011
# 0.01       6                  300      0.4941347  0.3689203
# 0.01       6                  400      0.4952127  0.3726677
# 0.01       6                  500      0.4999746  0.3807221
# 0.05       2                  100      0.4887786  0.3618821
# 0.05       2                  200      0.4835015  0.3603163
# 0.05       2                  300      0.4797725  0.3593039
# 0.05       2                  400      0.4724015  0.3513662
# 0.05       2                  500      0.4729108  0.3530740
# 0.05       3                  100      0.4835159  0.3576287
# 0.05       3                  200      0.4867187  0.3669540
# 0.05       3                  300      0.4755142  0.3555248
# 0.05       3                  400      0.4643832  0.3424781
# 0.05       3                  500      0.4632881  0.3417561
# 0.05       4                  100      0.4899046  0.3674050
# 0.05       4                  200      0.4781879  0.3569036
# 0.05       4                  300      0.4675408  0.3461888
# 0.05       4                  400      0.4702314  0.3500055
# 0.05       4                  500      0.4622355  0.3410007
# 0.05       5                  100      0.4824465  0.3585318
# 0.05       5                  200      0.4681235  0.3451705
# 0.05       5                  300      0.4617375  0.3388962
# 0.05       5                  400      0.4601447  0.3375523
# 0.05       5                  500      0.4574624  0.3344247
# 0.05       6                  100      0.4931267  0.3728877
# 0.05       6                  200      0.4830258  0.3635421
# 0.05       6                  300      0.4728797  0.3515108
# 0.05       6                  400      0.4686328  0.3479033
# 0.05       6                  500      0.4590580  0.3364391
# 0.10       2                  100      0.4803100  0.3588113
# 0.10       2                  200      0.4776675  0.3580203
# 0.10       2                  300      0.4728688  0.3548918
# 0.10       2                  400      0.4643465  0.3453821
# 0.10       2                  500      0.4510792  0.3301807
# 0.10       3                  100      0.4760572  0.3551065
# 0.10       3                  200      0.4680787  0.3486637
# 0.10       3                  300      0.4579693  0.3377000
# 0.10       3                  400      0.4504996  0.3282323
# 0.10       3                  500      0.4382622  0.3146251
# 0.10       4                  100      0.4787086  0.3590956
# 0.10       4                  200      0.4505529  0.3272936
# 0.10       4                  300      0.4505810  0.3289967
# 0.10       4                  400      0.4548449  0.3342924
# 0.10       4                  500      0.4484534  0.3265573
# 0.10       5                  100      0.4739578  0.3537030
# 0.10       5                  200      0.4707802  0.3501262
# 0.10       5                  300      0.4622946  0.3407944
# 0.10       5                  400      0.4564209  0.3334084
# 0.10       5                  500      0.4612167  0.3395150
# 0.10       6                  100      0.4660041  0.3442768
# 0.10       6                  200      0.4612366  0.3400700
# 0.10       6                  300      0.4648897  0.3440943
# 0.10       6                  400      0.4616783  0.3410621
# 0.10       6                  500      0.4595731  0.3380809
# 
# Tuning parameter 'n.minobsinnode' was held constant at a value of 10
# Accuracy was used to select the optimal model using the largest value.
# The final values used for the model were n.trees = 500, interaction.depth = 6, shrinkage = 0.01
# and n.minobsinnode = 10.